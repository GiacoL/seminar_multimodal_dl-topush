@Manual{rlang,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2018},
  url = {https://www.R-project.org/},
}

<!-- references for chapter 2 -->
<!-- references for 2.1 -->
@inproceedings{cornia2020m2,
  title={{Meshed-Memory Transformer for Image Captioning}},
  author={Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2020}
}

@article{bordes2020incorporating,
  title={Incorporating visual semantics into sentence representations within a grounded space},
  author={Bordes, Patrick and Zablocki, Eloi and Soulier, Laure and Piwowarski, Benjamin and Gallinari, Patrick},
  journal={arXiv preprint arXiv:2002.02734},
  year={2020}
}

@article{harnad1990symbol,
  title={The symbol grounding problem},
  author={Harnad, Stevan},
  journal={Physica D: Nonlinear Phenomena},
  volume={42},
  number={1-3},
  pages={335--346},
  year={1990},
  publisher={Elsevier}
}

@InProceedings{mccoco,
author="Lin, Tsung-Yi
and Maire, Michael
and Belongie, Serge
and Hays, James
and Perona, Pietro
and Ramanan, Deva
and Doll{\'a}r, Piotr
and Zitnick, C. Lawrence",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Microsoft COCO: Common Objects in Context",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="740--755",
abstract="We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.",
isbn="978-3-319-10602-1"
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{silberer2012grounded,
  title={Grounded models of semantic representation},
  author={Silberer, Carina and Lapata, Mirella},
  booktitle={Tsujii J, Henderson J, Pa{\c{s}}ca M, editors. Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning; 2012 Jul 12--14; Jeju Island, Korea. Stroudsburg: ACL; 2012. p. 1423-33.},
  year={2012},
  organization={ACL (Association for Computational Linguistics)}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{baevski2022data2vec,
  title={Data2vec: A general framework for self-supervised learning in speech, vision and language},
  author={Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  journal={arXiv preprint arXiv:2202.03555},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  journal={arXiv preprint arXiv:2204.14198},
  year={2022}
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{uppal2022multimodal,
  title={Multimodal research in vision and language: A review of current and emerging trends},
  author={Uppal, Shagun and Bhagat, Sarthak and Hazarika, Devamanyu and Majumder, Navonil and Poria, Soujanya and Zimmermann, Roger and Zadeh, Amir},
  journal={Information Fusion},
  volume={77},
  pages={149--171},
  year={2022},
  publisher={Elsevier}
}

@InProceedings{ramesh2021dalle,
  title = 	 {Zero-Shot Text-to-Image Generation},
  author =       {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8821--8831},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/ramesh21a.html},
  abstract = 	 {Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.}
}
@article{nichol2021glide,
  author    = {Alex Nichol and
               Prafulla Dhariwal and
               Aditya Ramesh and
               Pranav Shyam and
               Pamela Mishkin and
               Bob McGrew and
               Ilya Sutskever and
               Mark Chen},
  title     = {{GLIDE:} Towards Photorealistic Image Generation and Editing with
               Text-Guided Diffusion Models},
  journal   = {CoRR},
  volume    = {abs/2112.10741},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.10741},
  eprinttype = {arXiv},
  eprint    = {2112.10741},
  timestamp = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-10741.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{DeepPAMM,
  doi = {10.48550/ARXIV.2202.07423},
  
  url = {https://arxiv.org/abs/2202.07423},
  
  author = {Kopper, Philipp and Wiegrebe, Simon and Bischl, Bernd and Bender, Andreas and Rügamer, David},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {DeepPAMM: Deep Piecewise Exponential Additive Mixed Models for Complex Hazard Structures in Survival Analysis},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@INPROCEEDINGS{DeepConvSurv,
  author={Zhu, Xinliang and Yao, Jiawen and Huang, Junzhou},
  booktitle={2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Deep convolutional neural network for survival analysis with pathological images}, 
  year={2016},
  volume={},
  number={},
  pages={544-547},
  doi={10.1109/BIBM.2016.7822579}
}
@InProceedings{DeepCorrSurv,
author="Yao, Jiawen
and Zhu, Xinliang
and Zhu, Feiyun
and Huang, Junzhou",
editor="Descoteaux, Maxime
and Maier-Hein, Lena
and Franz, Alfred
and Jannin, Pierre
and Collins, D. Louis
and Duchesne, Simon",
title="Deep Correlational Learning for Survival Prediction from Multi-modality Data",
booktitle="Medical Image Computing and Computer-Assisted Intervention − MICCAI 2017",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="406--414",
isbn="978-3-319-66185-8"
}
@article{WideandDeepSurvival,
  author    = {Sebastian P{\"{o}}lsterl and
               Ignacio Sarasua and
               Benjam{\'{\i}}n Guti{\'{e}}rrez{-}Becker and
               Christian Wachinger},
  title     = {A Wide and Deep Neural Network for Survival Analysis from Anatomical
               Shape and Tabular Clinical Data},
  journal   = {CoRR},
  volume    = {abs/1909.03890},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.03890},
  eprinttype = {arXiv},
  eprint    = {1909.03890},
  timestamp = {Sat, 23 Jan 2021 01:20:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-03890.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DeepGaussianProcessCropPred,
author = {You, Jiaxuan and Li, Xiaocheng and Low, Melvin and Lobell, David and Ermon, Stefano},
title = {Deep Gaussian Process for Crop Yield Prediction Based on Remote Sensing Data},
year = {2017},
publisher = {AAAI Press},
abstract = {Agricultural monitoring, especially in developing countries, can help prevent famine and support humanitarian efforts. A central challenge is yield estimation, i.e., predicting crop yields before harvest.We introduce a scalable, accurate, and inexpensive method to predict crop yields using publicly available remote sensing data. Our approach improves existing techniques in three ways. First, we forego hand-crafted features traditionally used in the remote sensing community and propose an approach based on modern representation learning ideas. We also introduce a novel dimensionality reduction technique that allows us to train a Convolutional Neural Network or Long-short Term Memory network and automatically learn useful features even when labeled training data are scarce. Finally, we incorporate a Gaussian Process component to explicitly model the spatio-temporal structure of the data and further improve accuracy. We evaluate our approach on county-level soybean yield prediction in the U.S. and show that it outperforms competing techniques.},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
pages = {4559–4565},
numpages = {7},
location = {San Francisco, California, USA},
series = {AAAI'17}
}
@article{Law_2019,
	doi = {10.1145/3342240},
  
	url = {https://doi.org/10.1145%2F3342240},
  
	year = 2019,
	month = {sep},
  
	publisher = {Association for Computing Machinery ({ACM})},
  
	volume = {10},
  
	number = {5},
  
	pages = {1--19},
  
	author = {Stephen Law and Brooks Paige and Chris Russell},
  
	title = {Take a Look Around},
  
	journal = {{ACM} Transactions on Intelligent Systems and Technology}
}
@article{JeanEtAl,
author = {Neal Jean  and Marshall Burke  and Michael Xie  and W. Matthew Davis  and David B. Lobell  and Stefano Ermon },
title = {Combining satellite imagery and machine learning to predict poverty},
journal = {Science},
volume = {353},
number = {6301},
pages = {790-794},
year = {2016},
doi = {10.1126/science.aaf7894},
URL = {https://www.science.org/doi/abs/10.1126/science.aaf7894},
eprint = {https://www.science.org/doi/pdf/10.1126/science.aaf7894}
}
@article{Sardelich2018MultimodalDL,
  title={Multimodal deep learning for short-term stock volatility prediction},
  author={Marcelo Sardelich and Suresh Manandhar},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.10479}
}
@inproceedings{WideDeepNN,
author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
title = {Wide &amp; Deep Learning for Recommender Systems},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988454},
doi = {10.1145/2988450.2988454},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {7–10},
numpages = {4},
keywords = {Wide &amp; Deep Learning, Recommender Systems},
location = {Boston, MA, USA},
series = {DLRS 2016}
}
@misc{SSDDR,
  doi = {10.48550/ARXIV.2002.05777},
  
  url = {https://arxiv.org/abs/2002.05777},
  
  author = {Rügamer, David and Kolb, Chris and Klein, Nadja},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Semi-Structured Distributional Regression -- Extending Structured Additive Models by Arbitrary Deep Neural Networks and Data Modalities},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{HuangEtAl,
author = {Huang, Shih-Cheng and Pareek, Anuj and Seyyedi, Saeed and Banerjee, Imon and Lungren, Matthew},
year = {2020},
month = {12},
pages = {},
title = {Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines},
volume = {3},
journal = {npj Digital Medicine},
doi = {10.1038/s41746-020-00341-z}
}
@article{GoogleMappingBuilding,
  author    = {Wojciech Sirko and
               Sergii Kashubin and
               Marvin Ritter and
               Abigail Annkah and
               Yasser Salah Eddine Bouchareb and
               Yann N. Dauphin and
               Daniel Keysers and
               Maxim Neumann and
               Moustapha Ciss{\'{e}} and
               John Quinn},
  title     = {Continental-Scale Building Detection from High Resolution Satellite
               Imagery},
  journal   = {CoRR},
  volume    = {abs/2107.12283},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.12283},
  eprinttype = {arXiv},
  eprint    = {2107.12283},
  timestamp = {Tue, 03 Aug 2021 09:13:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-12283.bib},

<!-- references for 2.4 -->

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{yuan2021florence,
  title={Florence: A New Foundation Model for Computer Vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}

@article{yu2022coca,
  title={CoCa: Contrastive Captioners are Image-Text Foundation Models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@Article{Mikolov2013,
  author      = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  title       = {Efficient Estimation of Word Representations in Vector Space},
  year        = {2013},
  abstract    = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  date        = {2013-01-16},
  eprint      = {1301.3781},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1301.3781v3:PDF},
  keywords    = {cs.CL},
}

@Article{Bojanowski2016,
  author      = {Piotr Bojanowski and Edouard Grave and Armand Joulin and Tomas Mikolov},
  title       = {Enriching Word Vectors with Subword Information},
  year        = {2016},
  abstract    = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character $n$-grams. A vector representation is associated to each character $n$-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
  date        = {2016-07-15},
  eprint      = {1607.04606},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1607.04606v2:PDF},
  keywords    = {cs.CL, cs.LG},
}

@Article{Bahdanau2014,
  author      = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  title       = {Neural Machine Translation by Jointly Learning to Align and Translate},
  year        = {2014},
  abstract    = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  date        = {2014-09-01},
  eprint      = {1409.0473},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1409.0473v7:PDF},
  keywords    = {cs.CL, cs.LG, cs.NE, stat.ML},
}

@Article{Sutskever2014,
  author      = {Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
  title       = {Sequence to Sequence Learning with Neural Networks},
  year        = {2014},
  abstract    = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
  date        = {2014-09-10},
  eprint      = {1409.3215},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1409.3215v3:PDF},
  keywords    = {cs.CL, cs.LG},
}

@Article{Devlin2018,
  author      = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  title       = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year        = {2018},
  abstract    = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  date        = {2018-10-11},
  eprint      = {1810.04805},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.04805v2:PDF},
  keywords    = {cs.CL},
}

@Article{Raffel2019,
  author      = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title       = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  year        = {2019},
  abstract    = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
  date        = {2019-10-23},
  eprint      = {1910.10683},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1910.10683v3:PDF},
  keywords    = {cs.LG, cs.CL, stat.ML},
}

@article{ResNet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{EfficientNet,
  author    = {Mingxing Tan and
               Quoc V. Le},
  title     = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1905.11946},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.11946},
  eprinttype = {arXiv},
  eprint    = {1905.11946},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-11946.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{SimCLR,
  author    = {Ting Chen and
               Simon Kornblith and
               Mohammad Norouzi and
               Geoffrey E. Hinton},
  title     = {A Simple Framework for Contrastive Learning of Visual Representations},
  journal   = {CoRR},
  volume    = {abs/2002.05709},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.05709},
  eprinttype = {arXiv},
  eprint    = {2002.05709},
  timestamp = {Fri, 14 Feb 2020 12:07:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-05709.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{SwAV,
  author    = {Mathilde Caron and
               Ishan Misra and
               Julien Mairal and
               Priya Goyal and
               Piotr Bojanowski and
               Armand Joulin},
  title     = {Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
  journal   = {CoRR},
  volume    = {abs/2006.09882},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.09882},
  eprinttype = {arXiv},
  eprint    = {2006.09882},
  timestamp = {Tue, 23 Jun 2020 17:57:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-09882.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@article{BYOL,
  author    = {Jean{-}Bastien Grill and
               Florian Strub and
               Florent Altch{\'{e}} and
               Corentin Tallec and
               Pierre H. Richemond and
               Elena Buchatskaya and
               Carl Doersch and
               Bernardo {\'{A}}vila Pires and
               Zhaohan Daniel Guo and
               Mohammad Gheshlaghi Azar and
               Bilal Piot and
               Koray Kavukcuoglu and
               R{\'{e}}mi Munos and
               Michal Valko},
  title     = {Bootstrap Your Own Latent: {A} New Approach to Self-Supervised Learning},
  journal   = {CoRR},
  volume    = {abs/2006.07733},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.07733},
  eprinttype = {arXiv},
  eprint    = {2006.07733},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-07733.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@article{ImageT,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  journal   = {CoRR},
  volume    = {abs/2010.11929},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11929},
  eprinttype = {arXiv},
  eprint    = {2010.11929},
  timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
