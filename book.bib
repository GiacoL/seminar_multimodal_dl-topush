@Manual{rlang,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2018},
  url = {https://www.R-project.org/},
}

% references for chapter 2
% references for 2.1
@inproceedings{cornia2020m2,
  title={{Meshed-Memory Transformer for Image Captioning}},
  author={Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2020}
}

@article{bordes2020incorporating,
  title={Incorporating visual semantics into sentence representations within a grounded space},
  author={Bordes, Patrick and Zablocki, Eloi and Soulier, Laure and Piwowarski, Benjamin and Gallinari, Patrick},
  journal={arXiv preprint arXiv:2002.02734},
  year={2020}
}

@article{harnad1990symbol,
  title={The symbol grounding problem},
  author={Harnad, Stevan},
  journal={Physica D: Nonlinear Phenomena},
  volume={42},
  number={1-3},
  pages={335--346},
  year={1990},
  publisher={Elsevier}
}

@InProceedings{mccoco,
author="Lin, Tsung-Yi
and Maire, Michael
and Belongie, Serge
and Hays, James
and Perona, Pietro
and Ramanan, Deva
and Doll{\'a}r, Piotr
and Zitnick, C. Lawrence",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Microsoft COCO: Common Objects in Context",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="740--755",
abstract="We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.",
isbn="978-3-319-10602-1"
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{silberer2012grounded,
  title={Grounded models of semantic representation},
  author={Silberer, Carina and Lapata, Mirella},
  booktitle={Tsujii J, Henderson J, Pa{\c{s}}ca M, editors. Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning; 2012 Jul 12--14; Jeju Island, Korea. Stroudsburg: ACL; 2012. p. 1423-33.},
  year={2012},
  organization={ACL (Association for Computational Linguistics)}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{baevski2022data2vec,
  title={Data2vec: A general framework for self-supervised learning in speech, vision and language},
  author={Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  journal={arXiv preprint arXiv:2202.03555},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  journal={arXiv preprint arXiv:2204.14198},
  year={2022}
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{uppal2022multimodal,
  title={Multimodal research in vision and language: A review of current and emerging trends},
  author={Uppal, Shagun and Bhagat, Sarthak and Hazarika, Devamanyu and Majumder, Navonil and Poria, Soujanya and Zimmermann, Roger and Zadeh, Amir},
  journal={Information Fusion},
  volume={77},
  pages={149--171},
  year={2022},
  publisher={Elsevier}
}

@InProceedings{ramesh2021dalle,
  title = 	 {Zero-Shot Text-to-Image Generation},
  author =       {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8821--8831},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/ramesh21a.html},
  abstract = 	 {Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.}
}
@article{nichol2021glide,
  author    = {Alex Nichol and
               Prafulla Dhariwal and
               Aditya Ramesh and
               Pranav Shyam and
               Pamela Mishkin and
               Bob McGrew and
               Ilya Sutskever and
               Mark Chen},
  title     = {{GLIDE:} Towards Photorealistic Image Generation and Editing with
               Text-Guided Diffusion Models},
  journal   = {CoRR},
  volume    = {abs/2112.10741},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.10741},
  eprinttype = {arXiv},
  eprint    = {2112.10741},
  timestamp = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-10741.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{DeepPAMM,
  doi = {10.48550/ARXIV.2202.07423},

  url = {https://arxiv.org/abs/2202.07423},

  author = {Kopper, Philipp and Wiegrebe, Simon and Bischl, Bernd and Bender, Andreas and Rügamer, David},

  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {DeepPAMM: Deep Piecewise Exponential Additive Mixed Models for Complex Hazard Structures in Survival Analysis},

  publisher = {arXiv},

  year = {2022},

  copyright = {arXiv.org perpetual, non-exclusive license}
}
@INPROCEEDINGS{DeepConvSurv,
  author={Zhu, Xinliang and Yao, Jiawen and Huang, Junzhou},
  booktitle={2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  title={Deep convolutional neural network for survival analysis with pathological images},
  year={2016},
  volume={},
  number={},
  pages={544-547},
  doi={10.1109/BIBM.2016.7822579}
}
@InProceedings{DeepCorrSurv,
author="Yao, Jiawen
and Zhu, Xinliang
and Zhu, Feiyun
and Huang, Junzhou",
editor="Descoteaux, Maxime
and Maier-Hein, Lena
and Franz, Alfred
and Jannin, Pierre
and Collins, D. Louis
and Duchesne, Simon",
title="Deep Correlational Learning for Survival Prediction from Multi-modality Data",
booktitle="Medical Image Computing and Computer-Assisted Intervention − MICCAI 2017",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="406--414",
isbn="978-3-319-66185-8"
}
@article{WideandDeepSurvival,
  author    = {Sebastian P{\"{o}}lsterl and
               Ignacio Sarasua and
               Benjam{\'{\i}}n Guti{\'{e}}rrez{-}Becker and
               Christian Wachinger},
  title     = {A Wide and Deep Neural Network for Survival Analysis from Anatomical
               Shape and Tabular Clinical Data},
  journal   = {CoRR},
  volume    = {abs/1909.03890},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.03890},
  eprinttype = {arXiv},
  eprint    = {1909.03890},
  timestamp = {Sat, 23 Jan 2021 01:20:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-03890.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DeepGaussianProcessCropPred,
author = {You, Jiaxuan and Li, Xiaocheng and Low, Melvin and Lobell, David and Ermon, Stefano},
title = {Deep Gaussian Process for Crop Yield Prediction Based on Remote Sensing Data},
year = {2017},
publisher = {AAAI Press},
abstract = {Agricultural monitoring, especially in developing countries, can help prevent famine and support humanitarian efforts. A central challenge is yield estimation, i.e., predicting crop yields before harvest.We introduce a scalable, accurate, and inexpensive method to predict crop yields using publicly available remote sensing data. Our approach improves existing techniques in three ways. First, we forego hand-crafted features traditionally used in the remote sensing community and propose an approach based on modern representation learning ideas. We also introduce a novel dimensionality reduction technique that allows us to train a Convolutional Neural Network or Long-short Term Memory network and automatically learn useful features even when labeled training data are scarce. Finally, we incorporate a Gaussian Process component to explicitly model the spatio-temporal structure of the data and further improve accuracy. We evaluate our approach on county-level soybean yield prediction in the U.S. and show that it outperforms competing techniques.},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
pages = {4559–4565},
numpages = {7},
location = {San Francisco, California, USA},
series = {AAAI'17}
}
@article{Law_2019,
	doi = {10.1145/3342240},

	url = {https://doi.org/10.1145%2F3342240},

	year = 2019,
	month = {sep},

	publisher = {Association for Computing Machinery ({ACM})},

	volume = {10},

	number = {5},

	pages = {1--19},

	author = {Stephen Law and Brooks Paige and Chris Russell},

	title = {Take a Look Around},

	journal = {{ACM} Transactions on Intelligent Systems and Technology}
}
@article{JeanEtAl,
author = {Neal Jean  and Marshall Burke  and Michael Xie  and W. Matthew Davis  and David B. Lobell  and Stefano Ermon },
title = {Combining satellite imagery and machine learning to predict poverty},
journal = {Science},
volume = {353},
number = {6301},
pages = {790-794},
year = {2016},
doi = {10.1126/science.aaf7894},
URL = {https://www.science.org/doi/abs/10.1126/science.aaf7894},
eprint = {https://www.science.org/doi/pdf/10.1126/science.aaf7894}
}
@article{Sardelich2018MultimodalDL,
  title={Multimodal deep learning for short-term stock volatility prediction},
  author={Marcelo Sardelich and Suresh Manandhar},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.10479}
}
@inproceedings{WideDeepNN,
author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
title = {Wide &amp; Deep Learning for Recommender Systems},
year = {2016},
isbn = {9781450347952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988450.2988454},
doi = {10.1145/2988450.2988454},
booktitle = {Proceedings of the 1st Workshop on Deep Learning for Recommender Systems},
pages = {7–10},
numpages = {4},
keywords = {Wide &amp; Deep Learning, Recommender Systems},
location = {Boston, MA, USA},
series = {DLRS 2016}
}
@misc{SSDDR,
  doi = {10.48550/ARXIV.2002.05777},

  url = {https://arxiv.org/abs/2002.05777},

  author = {Rügamer, David and Kolb, Chris and Klein, Nadja},

  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {Semi-Structured Distributional Regression -- Extending Structured Additive Models by Arbitrary Deep Neural Networks and Data Modalities},

  publisher = {arXiv},

  year = {2020},

  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{HuangEtAl,
author = {Huang, Shih-Cheng and Pareek, Anuj and Seyyedi, Saeed and Banerjee, Imon and Lungren, Matthew},
year = {2020},
month = {12},
pages = {},
title = {Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines},
volume = {3},
journal = {npj Digital Medicine},
doi = {10.1038/s41746-020-00341-z}
}
@article{GoogleMappingBuilding,
  author    = {Wojciech Sirko and
               Sergii Kashubin and
               Marvin Ritter and
               Abigail Annkah and
               Yasser Salah Eddine Bouchareb and
               Yann N. Dauphin and
               Daniel Keysers and
               Maxim Neumann and
               Moustapha Ciss{\'{e}} and
               John Quinn},
  title     = {Continental-Scale Building Detection from High Resolution Satellite
               Imagery},
  journal   = {CoRR},
  volume    = {abs/2107.12283},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.12283},
  eprinttype = {arXiv},
  eprint    = {2107.12283},
  timestamp = {Tue, 03 Aug 2021 09:13:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-12283.bib}
}

% references for 2.4

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{yuan2021florence,
  title={Florence: A New Foundation Model for Computer Vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}

@article{ramesh2022hierarchical,
  title={Hierarchical Text-Conditional Image Generation with CLIP Latents. 2022},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{zhang2020contrastive,
  title={Contrastive learning of medical visual representations from paired images and text},
  author={Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D and Langlotz, Curtis P},
  journal={arXiv preprint arXiv:2010.00747},
  year={2020}
}

@online{sutton2019bitterlesson,
  author = {R. S. Sutton},
  title = {The Bitter Lesson},
  date = {2019-03-13},
  url = {http://www.incompleteideas.net/IncIdeas/BitterLesson.htwml}
}

@online{openai2021clipblog,
  author = {OpenAI},
  title = {CLIP: Connection Text and Images},
  date = {2021-01-05},
  url = {https://openai.com/blog/clip/}
}

@online{alford2021alignparams,
  author = {A. Alford},
  title = {Google Announces 800M Parameter Vision-Language AI Model ALIGN},
  date = {2021-07-20},
  url = {https://www.infoq.com/news/2021/07/google-vision-language-ai/}
}

@online{schuhmann2022laion,
  author = {C. Schuhmann},
  title = {Laion-400-Million Open Dataset},
  date = {2022-07-07},
  url = {https://laion.ai/blog/laion-400-open-dataset/}
}

@online{solawetz2021florenceopen,
  author = {J. Solawetz},
  title = {Florence: A New Foundation for Computer Vision},
  date = {2021-12-09},
  url = {https://blog.roboflow.com/florence-a-new-foundational-model-for-computer-vision/}
}

@inproceedings{jia2021scaling,
  title = {Scaling up visual and vision-language representation learning with noisy text supervision},
  author = {Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle = {International Conference on Machine Learning},
  pages = {4904--4916},
  year = {2021},
  organization = {PMLR}
}

@inproceedings{tian2020contrastive,
  title={Contrastive multiview coding},
  author={Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  booktitle={European conference on computer vision},
  pages={776--794},
  year={2020},
  organization={Springer}
}

% end 2.4

@article{yu2022coca,
  title={CoCa: Contrastive Captioners are Image-Text Foundation Models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@Article{Mikolov2013,
  author      = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  title       = {Efficient Estimation of Word Representations in Vector Space},
  year        = {2013},
  abstract    = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  date        = {2013-01-16},
  eprint      = {1301.3781},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1301.3781v3:PDF},
  keywords    = {cs.CL},
}


@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@Article{Bojanowski2016,
  author      = {Piotr Bojanowski and Edouard Grave and Armand Joulin and Tomas Mikolov},
  title       = {Enriching Word Vectors with Subword Information},
  year        = {2016},
  abstract    = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character $n$-grams. A vector representation is associated to each character $n$-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
  date        = {2016-07-15},
  eprint      = {1607.04606},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1607.04606v2:PDF},
  keywords    = {cs.CL, cs.LG},
}

@Article{Bahdanau2014,
  author      = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  title       = {Neural Machine Translation by Jointly Learning to Align and Translate},
  year        = {2014},
  abstract    = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  date        = {2014-09-01},
  eprint      = {1409.0473},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1409.0473v7:PDF},
  keywords    = {cs.CL, cs.LG, cs.NE, stat.ML},
}

@Article{Sutskever2014,
  author      = {Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
  title       = {Sequence to Sequence Learning with Neural Networks},
  year        = {2014},
  abstract    = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
  date        = {2014-09-10},
  eprint      = {1409.3215},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1409.3215v3:PDF},
  keywords    = {cs.CL, cs.LG},
}

@Article{Devlin2018,
  author      = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  title       = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year        = {2018},
  abstract    = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  date        = {2018-10-11},
  eprint      = {1810.04805},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.04805v2:PDF},
  keywords    = {cs.CL},
}

@Article{Raffel2019,
  author      = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title       = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  year        = {2019},
  abstract    = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
  date        = {2019-10-23},
  eprint      = {1910.10683},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1910.10683v3:PDF},
  keywords    = {cs.LG, cs.CL, stat.ML},
}

@article{ResNet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  eprinttype = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{EfficientNet,
  author    = {Mingxing Tan and
               Quoc V. Le},
  title     = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1905.11946},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.11946},
  eprinttype = {arXiv},
  eprint    = {1905.11946},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-11946.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{SimCLR,
  author    = {Ting Chen and
               Simon Kornblith and
               Mohammad Norouzi and
               Geoffrey E. Hinton},
  title     = {A Simple Framework for Contrastive Learning of Visual Representations},
  journal   = {CoRR},
  volume    = {abs/2002.05709},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.05709},
  eprinttype = {arXiv},
  eprint    = {2002.05709},
  timestamp = {Fri, 14 Feb 2020 12:07:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-05709.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{SwAV,
  author    = {Mathilde Caron and
               Ishan Misra and
               Julien Mairal and
               Priya Goyal and
               Piotr Bojanowski and
               Armand Joulin},
  title     = {Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
  journal   = {CoRR},
  volume    = {abs/2006.09882},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.09882},
  eprinttype = {arXiv},
  eprint    = {2006.09882},
  timestamp = {Tue, 23 Jun 2020 17:57:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-09882.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@article{BYOL,
  author    = {Jean{-}Bastien Grill and
               Florian Strub and
               Florent Altch{\'{e}} and
               Corentin Tallec and
               Pierre H. Richemond and
               Elena Buchatskaya and
               Carl Doersch and
               Bernardo {\'{A}}vila Pires and
               Zhaohan Daniel Guo and
               Mohammad Gheshlaghi Azar and
               Bilal Piot and
               Koray Kavukcuoglu and
               R{\'{e}}mi Munos and
               Michal Valko},
  title     = {Bootstrap Your Own Latent: {A} New Approach to Self-Supervised Learning},
  journal   = {CoRR},
  volume    = {abs/2006.07733},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.07733},
  eprinttype = {arXiv},
  eprint    = {2006.07733},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-07733.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@article{ImageT,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  journal   = {CoRR},
  volume    = {abs/2010.11929},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11929},
  eprinttype = {arXiv},
  eprint    = {2010.11929},
  timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@article{rosset2020turing,
  title={Turing-NLG: A 17-billion-parameter language model by Microsoft},
  author={Rosset, Corby},
  journal={Microsoft Blog},
  volume={1},
  number={2},
  year={2020}
}
@article{gao2020pile,
  title={The pile: An 800gb dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}
@inproceedings{zhu2015aligning,
  title={Aligning books and movies: Towards story-like visual explanations by watching movies and reading books},
  author={Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={19--27},
  year={2015}
}


@incollection{fellbaum2010wordnet,
  title={WordNet},
  author={Fellbaum, Christiane},
  booktitle={Theory and applications of ontology: computer applications},
  pages={231--243},
  year={2010},
  publisher={Springer}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
  journal={arXiv preprint arXiv:1503.02531},
  volume={2},
  number={7},
  year={2015}
}

@inproceedings{sun2017revisiting,
  title={Revisiting unreasonable effectiveness of data in deep learning era},
  author={Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={843--852},
  year={2017}
}


@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{torralba2011unbiased,
  title={Unbiased look at dataset bias},
  author={Torralba, Antonio and Efros, Alexei A},
  booktitle={CVPR 2011},
  pages={1521--1528},
  year={2011},
  organization={IEEE}
}

@inproceedings{pont2020connecting,
  title={Connecting vision and language with localized narratives},
  author={Pont-Tuset, Jordi and Uijlings, Jasper and Changpinyo, Soravit and Soricut, Radu and Ferrari, Vittorio},
  booktitle={European conference on computer vision},
  pages={647--664},
  year={2020},
  organization={Springer}
}

@inproceedings{zhou2017scene,
  title={Scene parsing through ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={633--641},
  year={2017}
}

@article{young2014image,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  publisher={MIT Press}
}

@article{kuznetsova2020open,
  title={The open images dataset v4},
  author={Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and others},
  journal={International Journal of Computer Vision},
  volume={128},
  number={7},
  pages={1956--1981},
  year={2020},
  publisher={Springer}
}

@online{LocNarWeb,
    author = {Website},
    title = {Localized Narratives Data and Visualization},
    year = 2020,
    url = {https://google.github.io/localized-narratives},
    urldate = {2022-06-26}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  number={1},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@article{saharia2022photorealistic,
  title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}

@unknown{parti,
author = {Yu, Jiahui and Xu, Yuanzhong and Koh, Jing and Luong, Thang and Baid, Gunjan and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu and Hutchinson, Ben and Han, Wei and Parekh, Zarana and Li, Xin and Zhang, Han and Baldridge, Jason and Wu, Yonghui},
year = {2022},
month = {06},
pages = {},
title = {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
doi = {10.48550/arXiv.2206.10789}
}

@online{darkMatter,
    author = {Yann, Lecun and Misra Ishan},
    title = {Self-supervised learning: The dark matter of intelligence},
    year = 2021,
    url = {https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/},
    urldate = {2022-06-26}
}

@online{redditUsers,
    author = { MICHAEL BARTHEL, GALEN STOCKING, JESSE HOLCOMB AND AMY MITCHELL},
    title = {Reddit news users more likely to be male, young and digital in their news preferences},
    year = 2016,
    url = {https://www.pewresearch.org/journalism/2016/02/25/reddit-news-users-more-likely-to-be-male-young-and-digital-in-their-news-preferences/},
    urldate = {2022-08-07}
}

@online{coco_eval,
    author = {Mircosoft},
    title = {Evaluate:Detection},
    year = 2019,
    url = {https://cocodataset.org/#detection-eval
},
    urldate = {2022-07-09}
}

@online{unsupBrain,
    author = {Mineault, Patrick},
    title = {Unsupervised models of the brain},
    year = 2021,
    url = {https://xcorr.net/2021/12/31/2021-in-review-unsupervised-brain-models/},
    urldate = {2022-06-26}
}

@article{zhuang2021unsupervised,
  title={Unsupervised neural network models of the ventral visual stream},
  author={Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C and DiCarlo, James J and Yamins, Daniel LK},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={3},
  pages={e2014196118},
  year={2021},
  publisher={National Acad Sciences}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{bromley1993signature,
  title={Signature verification using a" siamese" time delay neural network},
  author={Bromley, Jane and Guyon, Isabelle and LeCun, Yann and S{\"a}ckinger, Eduard and Shah, Roopak},
  journal={Advances in neural information processing systems},
  volume={6},
  year={1993}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21271--21284},
  year={2020}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9650--9660},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@inproceedings{mahajan2018exploring,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={181--196},
  year={2018}
}

@article{kolesnikov2019large,
  title={Large scale learning of general visual representations for transfer},
  author={Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  journal={arXiv preprint arXiv:1912.11370},
  volume={2},
  number={8},
  year={2019},
  publisher={arXiv}
}

@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@article{rajpurkar2018know,
  title={Know what you don't know: Unanswerable questions for SQuAD},
  author={Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  journal={arXiv preprint arXiv:1806.03822},
  year={2018}
}

@article{srivastava2022beyond,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@article{bowman2021will,
  title={What Will it Take to Fix Benchmarking in Natural Language Understanding?},
  author={Bowman, Samuel R and Dahl, George E},
  journal={arXiv preprint arXiv:2104.02145},
  year={2021}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{recht2019imagenet,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={International Conference on Machine Learning},
  pages={5389--5400},
  year={2019},
  organization={PMLR}
}

@article{beyer2020we,
  title={Are we done with imagenet?},
  author={Beyer, Lucas and H{\'e}naff, Olivier J and Kolesnikov, Alexander and Zhai, Xiaohua and Oord, A{\"a}ron van den},
  journal={arXiv preprint arXiv:2006.07159},
  year={2020}
}

@article{li2022mask,
  title={Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation},
  author={Li, Feng and Zhang, Hao and Liu, Shilong and Zhang, Lei and Ni, Lionel M and Shum, Heung-Yeung and others},
  journal={arXiv preprint arXiv:2206.02777},
  year={2022}
}

@inproceedings{zhou2017scene,
  title={Scene parsing through ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={633--641},
  year={2017}
}

@inproceedings{koehn2005europarl,
  title={Europarl: A parallel corpus for statistical machine translation},
  author={Koehn, Philipp},
  booktitle={Proceedings of machine translation summit x: papers},
  pages={79--86},
  year={2005}
}

@misc{Gokaslan2019OpenWeb,
	title={OpenWebText Corpus},
	author={Aaron Gokaslan and Vanya Cohen},
	year={2019}
}


@article{xue2020mt5,
  title={mT5: A massively multilingual pre-trained text-to-text transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  journal={arXiv preprint arXiv:2010.11934},
  year={2020}
}

@article{wenzek2019ccnet,
  title={Ccnet: Extracting high quality monolingual datasets from web crawl data},
  author={Wenzek, Guillaume and Lachaux, Marie-Anne and Conneau, Alexis and Chaudhary, Vishrav and Guzm{\'a}n, Francisco and Joulin, Armand and Grave, Edouard},
  journal={arXiv preprint arXiv:1911.00359},
  year={2019}
}

@article{bandy2021addressing,
  title={Addressing" documentation debt" in machine learning research: A retrospective datasheet for bookcorpus},
  author={Bandy, Jack and Vincent, Nicholas},
  journal={arXiv preprint arXiv:2105.05241},
  year={2021}
}

@article{gao2017knowledge,
  title={Knowledge concentration: Learning 100k object classifiers in a single CNN},
  author={Gao, Jiyang and Li, Zhen and Nevatia, Ram and others},
  journal={arXiv preprint arXiv:1711.07607},
  year={2017}
}

@inproceedings{shao2019objects365,
  title={Objects365: A large-scale, high-quality dataset for object detection},
  author={Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8430--8439},
  year={2019}
}

@article{yuan2022wudaomm,
  title={WuDaoMM: A large-scale Multi-Modal Dataset for Pre-training models},
  author={Yuan, Sha and Shuai, Zhao and Jiahong, Leng and Zhao, Xue and Hanyu, Zhao and Jie, Tang},
  journal={arXiv preprint arXiv:2203.11480},
  year={2022}
}

@inproceedings{srinivasan2021wit,
  title={Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning},
  author={Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2443--2449},
  year={2021}
}

@article{tiedemann2018emerging,
  title={Emerging language spaces learned from massively multilingual corpora},
  author={Tiedemann, J{\"o}rg},
  journal={arXiv preprint arXiv:1802.00273},
  year={2018}
}

@article{mayer2014creating,
  title={Creating a massively parallel Bible corpus},
  author={Mayer, Thomas and Cysouw, Michael},
  journal={Oceania},
  volume={135},
  number={273},
  pages={40},
  year={2014}
}

@inproceedings{zellers2019recognition,
  title={From recognition to cognition: Visual commonsense reasoning},
  author={Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6720--6731},
  year={2019}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@inproceedings{zhang2016yin,
  title={Yin and yang: Balancing and answering binary visual questions},
  author={Zhang, Peng and Goyal, Yash and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5014--5022},
  year={2016}
}

@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}

@article{shekhar2017foil,
  title={Foil it! find one mismatch between image and language caption},
  author={Shekhar, Ravi and Pezzelle, Sandro and Klimovich, Yauhen and Herbelot, Aur{\'e}lie and Nabi, Moin and Sangineto, Enver and Bernardi, Raffaella},
  journal={arXiv preprint arXiv:1705.01359},
  year={2017}
}

@article{ribeiro2020beyond,
  title={Beyond accuracy: Behavioral testing of NLP models with CheckList},
  author={Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  journal={arXiv preprint arXiv:2005.04118},
  year={2020}
}

@inproceedings{parcalabescu-etal-2022-valse,
    title = "{VALSE}: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena",
    author = "Parcalabescu, Letitia  and
      Cafagna, Michele  and
      Muradjan, Lilitta  and
      Frank, Anette  and
      Calixto, Iacer  and
      Gatt, Albert",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.567",
    pages = "8253--8280",
    abstract = "We propose VALSE (Vision And Language Structured Evaluation), a novel benchmark designed for testing general-purpose pretrained vision and language (V{\&}L) models for their visio-linguistic grounding capabilities on specific linguistic phenomena. VALSE offers a suite of six tests covering various linguistic constructs. Solving these requires models to ground linguistic phenomena in the visual modality, allowing more fine-grained evaluations than hitherto possible. We build VALSE using methods that support the construction of valid foils, and report results from evaluating five widely-used V{\&}L models. Our experiments suggest that current models have considerable difficulty addressing most phenomena. Hence, we expect VALSE to serve as an important benchmark to measure future progress of pretrained V{\&}L models from a linguistic perspective, complementing the canonical task-centred V{\&}L evaluations.",
}

@article{sheng2019woman,
  title={The woman worked as a babysitter: On biases in language generation},
  author={Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  journal={arXiv preprint arXiv:1909.01326},
  year={2019}
}

@inproceedings{dhamala2021bold,
  title={Bold: Dataset and metrics for measuring biases in open-ended language generation},
  author={Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={862--872},
  year={2021}
}

@article{prabhu2020large,
  title={Large image datasets: A pyrrhic win for computer vision?},
  author={Prabhu, Vinay Uday and Birhane, Abeba},
  journal={arXiv preprint arXiv:2006.16923},
  year={2020}
}

@article{birhane2021multimodal,
  title={Multimodal datasets: misogyny, pornography, and malignant stereotypes},
  author={Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
  journal={arXiv preprint arXiv:2110.01963},
  year={2021}
}

@article{strubell2019energy,
  title={Energy and policy considerations for deep learning in NLP},
  author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  journal={arXiv preprint arXiv:1906.02243},
  year={2019}
}

@article{lottick2019energy,
  title={Energy Usage Reports: Environmental awareness as part of algorithmic accountability},
  author={Lottick, Kadan and Susai, Silvia and Friedler, Sorelle A and Wilson, Jonathan P},
  journal={arXiv preprint arXiv:1911.08354},
  year={2019}
}

@article{henderson2020towards,
  title={Towards the systematic reporting of the energy and carbon footprints of machine learning},
  author={Henderson, Peter and Hu, Jieru and Romoff, Joshua and Brunskill, Emma and Jurafsky, Dan and Pineau, Joelle},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={248},
  pages={1--43},
  year={2020}
}

@inproceedings{guo2016ms,
  title={Ms-celeb-1m: A dataset and benchmark for large-scale face recognition},
  author={Guo, Yandong and Zhang, Lei and Hu, Yuxiao and He, Xiaodong and Gao, Jianfeng},
  booktitle={European conference on computer vision},
  pages={87--102},
  year={2016},
  organization={Springer}
}
